{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e6ea370-66bf-45ea-aca6-9757228557c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MNIST' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f380bba1bf6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# load MNIST data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./dir_with_mnist_data_files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MNIST' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def norm(arr):\n",
    "    arr = arr.astype(np.float)\n",
    "    arr -= arr.min()\n",
    "    arr /= arr.max()\n",
    "    return arr\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # load MNIST data set\n",
    "    mnist = MNIST('./dir_with_mnist_data_files')\n",
    "    X, Y = minst.load_training()\n",
    "\n",
    "    # normalize inputs to 0-1 range\n",
    "    X = norm(X)\n",
    "\n",
    "    # split into train, validation, and test data sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,       Y,       test_size=10000, random_state=0)\n",
    "    X_train, X_val,  Y_train, Y_val  = train_test_split(X_train, Y_train, test_size=10000, random_state=0)\n",
    "\n",
    "    # --------------------------------------------------------------------------------\n",
    "    # set hyperparameters\n",
    "\n",
    "    learning_rate = 0.02 # from Erhan et el. (2010): median value in grid-search\n",
    "    total_units   =  800 # from Erhan et el. (2010): optimal for MNIST / only slightly worse than 1200 units when using InfiniteMNIST\n",
    "    total_epochs  =   50 # from Erhan et el. (2010): optimal for MNIST\n",
    "    batch_size    =  128 # seems like a representative sample; backprop literature often uses 256 or 512 samples\n",
    "\n",
    "    C = 100. # optimum for benchmark model according to sklearn docs: https://scikit-learn.org/stable/auto_examples/neural_networks/plot_rbm_logistic_classification.html#sphx-glr-auto-examples-neural-networks-plot-rbm-logistic-classification-py)\n",
    "\n",
    "    # TODO optimize using grid search, etc\n",
    "\n",
    "    # --------------------------------------------------------------------------------\n",
    "    # construct models\n",
    "\n",
    "    # RBM\n",
    "    rbm = BernoulliRBM(n_components=total_units, learning_rate=learning_rate, batch_size=batch_size, n_iter=total_epochs, verbose=1)\n",
    "\n",
    "    # \"output layer\"\n",
    "    logistic = LogisticRegression(C=C, solver='lbfgs', multi_class='multinomial', max_iter=200, verbose=1)\n",
    "\n",
    "    models = []\n",
    "    models.append(Pipeline(steps=[('logistic', clone(logistic))]))                                              # base model / benchmark\n",
    "    models.append(Pipeline(steps=[('rbm1', clone(rbm)), ('logistic', clone(logistic))]))                        # single RBM\n",
    "    models.append(Pipeline(steps=[('rbm1', clone(rbm)), ('rbm2', clone(rbm)), ('logistic', clone(logistic))]))  # RBM stack / DBN\n",
    "\n",
    "    # --------------------------------------------------------------------------------\n",
    "    # train and evaluate models\n",
    "\n",
    "    for model in models:\n",
    "        # train\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        # evaluate using validation set\n",
    "        print(\"Model performance:\\n%s\\n\" % (\n",
    "            classification_report(Y_val, model.predict(X_val))))\n",
    "\n",
    "    # TODO: after parameter optimization, evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6059e850-7f23-428e-a62f-c3fb5356e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30c0c4d7-c749-4678-a238-654db8b09954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd39b3d8-4c24-444e-9e73-2367e0e02664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
